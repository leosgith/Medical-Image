{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gj9FA9Is60G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "2209934c-2abb-4626-9db9-3d5a198fb949"
      },
      "source": [
        "#####actual program huh\n",
        "#####importing\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, Conv1D,MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#looking for an path in Google drive\n",
        "train_path = '/content/drive/My Drive/Colab Notebooks/chest_xray11/train'\n",
        "val_path = '/content/drive/My Drive/Colab Notebooks/chest_xray11/val'\n",
        "test_path = '/content/drive/My Drive/Colab Notebooks/chest_xray11/test'\n",
        "\n",
        "test_norm = ImageDataGenerator(rescale = 1./255)  #Image normalization\n",
        "\n",
        "#transofrming images into matrices to work with; batch size = 30\n",
        "train_batch = test_norm.flow_from_directory(train_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)\n",
        "test_batch = test_norm.flow_from_directory(test_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)\n",
        "val_batch = test_norm.flow_from_directory(val_path,target_size = (500,500),classes = ['NORMAL','PNEUMONIA'],batch_size=30)\n",
        "\n",
        "#neural network model building\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(80, (3,3), input_shape=(500, 500, 3), activation='relu', strides= 2))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
        "classifier.add(Conv2D(80, (3,3), activation='relu', strides= 2))\n",
        "classifier.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#classifier.add(Dense(50, activation='relu'))\n",
        "classifier.add(Dense(128, activation='relu'))\n",
        "classifier.add(Dense(128, activation='relu'))\n",
        "classifier.add(Dense(2, activation='softmax'))\n",
        "classifier.summary()\n",
        "\n",
        "#network compiling\n",
        "classifier.compile(loss = keras.losses.binary_crossentropy, optimizer = 'adam',metrics=['accuracy'])\n",
        "\n",
        "#it is stored in history, since it works out for graphics\n",
        "h = classifier.fit(train_batch,epochs = 1, steps_per_epoch=7,validation_data=val_batch,validation_steps=3)\n",
        "\n",
        "\n",
        "\n",
        "#printing overall accuracy\n",
        "\n",
        "#not sure whether it should be history or classifier here\n",
        "test_accu = classifier.evaluate_generator(test_batch,steps=10)\n",
        "print(\"Test accuracy is: \", test_accu[1]*100, '%' )\n",
        "\n",
        "\n",
        "\n",
        "#graphs \n",
        "'''\n",
        "#accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Validation set'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training set', 'Test set'], loc='upper left')\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "\n",
        "###in this part I try to figure out recall, precision and f1\n",
        "\n",
        "#getting predictions and reshaping\n",
        "pred = classifier.predict(test_batch)\n",
        "pred.shape\n",
        "p = pred.T.reshape(-1, 1)\n",
        "\n",
        "#making predictions either 0 or 1\n",
        "pred_final = np.where(p>0.5,1,0)\n",
        "pred_final \n",
        "\n",
        "\n",
        "#getting y_test once more, but dividing it into normal/ pneumonia (or 1/0) this time\n",
        "labels = ['NORMAL', 'PNEUMONIA']   \n",
        "\n",
        "def create_training_data(data_dir):              #creating the training data\n",
        "    \n",
        "    images = []\n",
        "    \n",
        "    for label in labels:\n",
        "        dir = os.path.join(data_dir,label)\n",
        "        class_num = labels.index(label)\n",
        "        \n",
        "        \n",
        "\n",
        "        for image in os.listdir(dir):    \n",
        "            \n",
        "            \n",
        "            images.append([class_num])\n",
        "            \n",
        "    return np.array(images)\n",
        "\n",
        "\n",
        "y_test = create_training_data('/content/drive/My Drive/Colab Notebooks/chest_xray11/test')\n",
        "\n",
        "#here we have different dimensions for goodness knows what reason\n",
        "print(y_test.shape)\n",
        "print(pred_final.shape)\n",
        "\n",
        "#function on getting recall, precision and f1\n",
        "def perf_measure(test_batch, pred_final):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(pred_final)): \n",
        "        if test_batch[i]==pred_final[i]==1:\n",
        "           TP += 1\n",
        "        if test_batch[i]==1 and test_batch[i]!=pred_final[i]:\n",
        "           FP += 1\n",
        "        if test_batch[i]==pred_final[i]==0:\n",
        "           TN += 1\n",
        "        if test_batch[i]==0 and test_batch[i]!=pred_final[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)\n",
        "\n",
        "\n",
        "\n",
        "#function use and getting actual numbers\n",
        "\n",
        "tp, fp, tn ,fn = perf_measure(y_test,pred_final)\n",
        "\n",
        "precision = tp/(tp+fp)\n",
        "recall = tp/(tp+fn)\n",
        "f_score = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "print(\"Recall of the model is {:.2f}\".format(recall))\n",
        "print(\"Precision of the model is {:.2f}\".format(precision))\n",
        "print(\"F-Score is {:.2f}\".format(f_score))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 249, 249, 80)      2240      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 83, 83, 80)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 41, 41, 80)        57680     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 80)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 13520)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1730688   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,807,378\n",
            "Trainable params: 1,807,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1\n",
            "7/7 [==============================] - 111s 16s/step - loss: 0.5938 - accuracy: 0.6905 - val_loss: 0.9944 - val_accuracy: 0.5000\n",
            "Test accuracy is:  61.666667461395264 %\n",
            "(624, 1)\n",
            "(1248, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-769be40f6a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-769be40f6a53>\u001b[0m in \u001b[0;36mperf_measure\u001b[0;34m(test_batch, pred_final)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpred_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m            \u001b[0mTP\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mpred_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 624 is out of bounds for axis 0 with size 624"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goXyBbRXtAno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "34589301-79e4-4f38-a35c-dea285d3f720"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}